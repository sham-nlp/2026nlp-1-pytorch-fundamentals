{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals - Assignment 1\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/sham-nlp/2026nlp-1-pytorch-fundamentals/blob/main/01_pytorch_assignment_student.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "**Name:** `Your Name Here`\n",
    "**Date:** `Insert Date`\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Complete the code sections marked with `# YOUR CODE HERE`.\n",
    "\n",
    "**Submission:** Submit this notebook with all cells executed and outputs visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# TODO: Create a 2x3 tensor with values 1 through 6\n",
    "# Hint: Use torch.tensor() or torch.arange() with .reshape()\n",
    "x = # YOUR CODE HERE\n",
    "\n",
    "print(\"Tensor x:\")\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "print(f\"Shape:   {x.shape}\")      # Expected: torch.Size([2, 3])\n",
    "print(f\"Dtype:   {x.dtype}\")      # Expected: torch.int64\n",
    "print(f\"Device:  {x.device}\")     # Expected: cpu\n",
    "print(f\"Stride:  {x.stride()}\")   # Expected: (3, 1)\n",
    "print(f\"Is contiguous: {x.is_contiguous()}\")  # Expected: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the same tensor but with dtype float32\n",
    "# Hint: Pass dtype=torch.float32 to torch.tensor(..., dtype=torch.float32)\n",
    "x_float = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Float tensor dtype: {x_float.dtype}\")  # Expected: torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Building a Linear Model\n",
    "\n",
    "Implement y = wx + b using PyTorch tensors with gradient tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: negative news ratio\n",
    "x = torch.tensor([[0.3], [0.7], [0.1], [0.5]])\n",
    "\n",
    "# Target: exchange rate increases\n",
    "y_true = torch.tensor([[12.0], [29.0], [4.0], [23.0]])\n",
    "\n",
    "print(f\"Input shape:  {x.shape}\")    # (4, 1) - 4 samples, 1 feature\n",
    "print(f\"Target shape: {y_true.shape}\")  # (4, 1) - 4 samples, 1 output\n",
    "\n",
    "# TODO: Initialize weight w and bias b\n",
    "# Use requires_grad=True so PyTorch tracks gradients\n",
    "# Initialize w to 0.5 and b to 0.0\n",
    "w = # YOUR CODE HERE\n",
    "b = # YOUR CODE HERE\n",
    "\n",
    "print(f\"\\nInitial w: {w.item():.2f}\")  # Expected: 0.50\n",
    "print(f\"Initial b: {b.item():.2f}\")  # Expected: 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the forward function: y_pred = x @ w + b\n",
    "def forward(x, w, b):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "# Test it\n",
    "y_pred = forward(x, w, b)\n",
    "print(\"Predictions with initial w, b:\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Loss and Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define MSE loss function\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return # YOUR CODE HERE\n",
    "\n",
    "# Compute loss\n",
    "loss = mse_loss(y_pred, y_true)\n",
    "print(f\"Initial loss: {loss.item():.2f}\")\n",
    "\n",
    "# TODO: Compute gradients using autograd\n",
    "# Hint: Call something on the loss [ loss.???() ]\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"\\nGradients computed!\")\n",
    "print(f\"dw (gradient of loss w.r.t. w): {w.grad.item():.2f}\")\n",
    "print(f\"db (gradient of loss w.r.t. b): {b.grad.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Manual Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "# TODO: Update parameters using gradient descent\n",
    "# w_new = w_old - learning_rate * gradient\n",
    "# Use torch.no_grad() context so this update isn't tracked\n",
    "with torch.no_grad():\n",
    "    w -= # YOUR CODE HERE\n",
    "    b -= # YOUR CODE HERE\n",
    "\n",
    "# TODO: Zero the gradients for next iteration\n",
    "# Hint: Set .grad to ???\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"After one update:\")\n",
    "print(f\"w: {w.item():.4f}\")\n",
    "print(f\"b: {b.item():.4f}\")\n",
    "\n",
    "# Check new predictions\n",
    "y_pred_new = forward(x, w, b)\n",
    "loss_new = mse_loss(y_pred_new, y_true)\n",
    "print(f\"\\nNew loss: {loss_new.item():.2f}\")\n",
    "print(f\"Old loss: {loss.item():.2f}\")\n",
    "print(f\"Loss decreased? {loss_new < loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Full Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset parameters\n",
    "w = torch.tensor([[0.5]], requires_grad=True)\n",
    "b = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Step 1: Forward pass\n",
    "    y_pred = # YOUR CODE HERE\n",
    "    \n",
    "    # Step 2: Compute loss\n",
    "    loss = # YOUR CODE HERE\n",
    "    \n",
    "    # Step 3: Backward pass\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Step 4: Update parameters\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "        b -= # YOUR CODE HERE\n",
    "    \n",
    "    # Step 5: Zero gradients\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Print progress every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch {epoch+1:4d} | Loss: {loss.item():.6f} | w: {w.item():.4f} | b: {b.item():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training complete!\")\n",
    "print(f\"Final w: {w.item():.4f} (expected: ~40.0)\")\n",
    "print(f\"Final b: {b.item():.4f} (expected: ~0.0)\")\n",
    "print(f\"Final loss: {mse_loss(forward(x, w, b), y_true).item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Test Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a prediction for 0.1 news ratio\n",
    "test_input = # YOUR CODE HERE torch.tensor([??])\n",
    "\n",
    "prediction = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Predicted exchange rate increase: {prediction.item():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Training with `nn.Linear` and Manual SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "x = torch.tensor([[0.3], [0.7], [0.1], [0.5]])\n",
    "y_true = torch.tensor([[12.0], [29.0], [4.0], [23.0]])\n",
    "\n",
    "# TODO: Create an nn.Linear layer with 1 input and 1 output\n",
    "# Hint: nn.Linear(in_features, out_features)\n",
    "model = # YOUR CODE HERE\n",
    "\n",
    "print(f\"Model: {model}\")\n",
    "print(f\"Initial weight: {model.weight.item():.4f}\")  # Random value\n",
    "print(f\"Initial bias: {model.bias.item():.4f}\")    # Random value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Method 1: Update Each Parameter Directly\n",
    "\n",
    "Update `model.weight` and `model.bias` separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "\n",
    "print(\"Training with Method 1: Direct parameter update\\n\")\n",
    "print(f\"{'Epoch':>6} | {'Loss':>10} | {'Weight':>8} | {'Bias':>8}\")\n",
    "print(\"-\" * 42)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Step 1: Forward pass\n",
    "    y_pred = # YOUR CODE HERE (hint: call model like a function)\n",
    "    \n",
    "    # Step 2: Compute loss\n",
    "    loss = # YOUR CODE HERE (hint: reuse mse_loss we coded earlier)\n",
    "    \n",
    "    # Step 3: Backward pass\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Step 4: Update parameters (IMPORTANT: use torch.no_grad()!)\n",
    "    # Hint: model.weight -= learning_rate * model.weight.grad\n",
    "    #       same for bias\n",
    "    with # YOUR CODE HERE :\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "    # Step 5: Zero the gradients\n",
    "    # Hint: model.weight.grad.zero_()\n",
    "    #       model.bias.grad.zero_()\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Print progress every 50 epochs\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"{epoch+1:6d} | {loss.item():10.6f} | {model.weight.item():8.4f} | {model.bias.item():8.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*42)\n",
    "print(f\"Final weight: {model.weight.item():.4f} (expected: ~4.0)\")\n",
    "print(f\"Final bias:   {model.bias.item():.4f} (expected: ~0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Method 2: Update Using `model.parameters()`\n",
    "\n",
    "Loop through all parameters automatically - more scalable for larger models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1, 1)\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "\n",
    "print(\"Training with Method 2: Using model.parameters()\\n\")\n",
    "print(f\"{'Epoch':>6} | {'Loss':>10} | {'Weight':>8} | {'Bias':>8}\")\n",
    "print(\"-\" * 42)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Step 1: Forward pass\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # Step 2: Compute loss\n",
    "    loss = ((y_pred - y_true) ** 2).mean()\n",
    "    \n",
    "    # Step 3: Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Step 4: Update parameters using model.parameters()\n",
    "    # This loops through BOTH weight and bias automatically!\n",
    "    # Hint: for param in model.parameters():\n",
    "    #           param -= learning_rate * param.grad\n",
    "    with torch.no_grad():\n",
    "        # YOUR CODE HERE\n",
    "    \n",
    "    # Step 5: Zero the gradients using model.parameters()\n",
    "    # Hint: for param in model.parameters():\n",
    "    #           param.grad.zero_()\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Print progress every 50 epochs\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"{epoch+1:6d} | {loss.item():10.6f} | {model.weight.item():8.4f} | {model.bias.item():8.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*42)\n",
    "print(f\"Final weight: {model.weight.item():.4f} (expected: ~4.0)\")\n",
    "print(f\"Final bias:   {model.bias.item():.4f} (expected: ~0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Challenge (Optional)\n",
    "\n",
    "Explore what happens with a different relationship.\n",
    "\n",
    "Generate data where y = 2x² + 3x + 1 and try to fit it.\n",
    "\n",
    "Hint: You'll need to create features [x, x²] and use a weight vector with 2 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here (optional challenge)\n",
    "# \n",
    "# Steps:\n",
    "# 1. Generate x values (e.g., torch.linspace(-2, 2, 50))\n",
    "# 2. Compute y = 2*x² + 3*x + 1\n",
    "# 3. Create feature matrix: [x, x²]\n",
    "# 4. Initialize weights [w1, w2] and bias b\n",
    "# 5. Train using the same loop as above\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
